{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d55213-77e2-4ffd-ab4e-5e20aabbc0bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array, concatenate, sign\n",
    "from math import pi, cos, sin, log, sqrt\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from scipy.sparse import csc_matrix\n",
    "from struct import pack, unpack, calcsize\n",
    "import zlib\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f3ba13d-e0a1-4202-aabf-fa2960dc60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(x, v_fmt):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = truncate(x[i], v_fmt)\n",
    "\n",
    "def truncate(value, format_spec):\n",
    "    \"\"\"Truncate the value to the specified format.\"\"\"\n",
    "    try:\n",
    "        return float(f\"{value:{format_spec}}\")\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Invalid format code '{format_spec}' for value '{value}'\") from e\n",
    "\n",
    "def write_vector_as_pairs(f, x, n0, v_fmt):\n",
    "    \"\"\"Write a sparse vector as a list of pairs (pos, value)\"\"\"\n",
    "    f.write(\"B\", int(n0))\n",
    "    pos_fmt = \"B\" if len(x) <= 256 else \"H\"\n",
    "    if n0 > 0:\n",
    "        for i, value in enumerate(x):\n",
    "            if value != 0:\n",
    "                f.write(pos_fmt, i)\n",
    "                quantized_value = truncate(value, v_fmt)\n",
    "                f.write(\"f\", float(quantized_value))     \n",
    "\n",
    "def write_vector(f, x, v_fmt):\n",
    "    quantize(x, v_fmt)\n",
    "    n0 = np.linalg.norm(x, 0)\n",
    "    write_vector_as_pairs(f, x, n0, v_fmt)\n",
    "\n",
    "def sub_image(im_data, N, i, j, k):\n",
    "    \"\"\"\n",
    "    Extracts a sub-image from a larger image array.\n",
    "\n",
    "    Parameters:\n",
    "    - im_data: The full image data as a NumPy array.\n",
    "    - N: The size of the block.\n",
    "    - i, j: The starting indices for the block.\n",
    "    - k: The channel index.\n",
    "\n",
    "    Returns:\n",
    "    - The extracted sub-image as a NumPy array.\n",
    "    \"\"\"\n",
    "    h0, h1, w0, w1 = i, i + N, j, j + N\n",
    "    return im_data[h0:h1, w0:w1, k]\n",
    "\n",
    "def set_sub_image(sub_img, im_data, N, i, j, k):\n",
    "    \"\"\"\n",
    "    Places a sub-image back into the larger image array.\n",
    "\n",
    "    Parameters:\n",
    "    - sub_img: The sub-image to be placed back.\n",
    "    - im_data: The full image data as a NumPy array.\n",
    "    - N: The size of the block.\n",
    "    - i, j: The starting indices for the block.\n",
    "    - k: The channel index.\n",
    "    \"\"\"\n",
    "    h0, h1, w0, w1 = i, i + N, j, j + N\n",
    "    im_data[h0:h1, w0:w1, k] = sub_img\n",
    "\n",
    "def mode_to_bpp(mode):\n",
    "    \"\"\"Convert image mode to bits per pixel.\"\"\"\n",
    "    if mode == 'L':  # 8-bit pixels, black and white\n",
    "        return 8\n",
    "    elif mode == 'RGB':  # 24-bit color\n",
    "        return 24\n",
    "    elif mode == 'RGBA':  # 32-bit color with alpha\n",
    "        return 32\n",
    "    elif mode == 'YCbCr':  # 24-bit color (YUV)\n",
    "        return 24\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported image mode: {mode}\")\n",
    "        \n",
    "def min_sparcity(max_error, N):\n",
    "    \"\"\"Calculate minimum sparsity based on max_error and block size N.\"\"\"\n",
    "    return int(np.ceil(max_error * N**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a36f3fa4-a6b0-4b8a-8e57-e290ff78470f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RawFile:\n",
    "    def __init__(self, name, mode):\n",
    "        \"\"\"Open file with name and mode\"\"\"\n",
    "        self.f = open(name, mode)\n",
    "        self.wnibble = None     # nibble pending to write\n",
    "        self.rnibble = None     # nibble pending to read\n",
    "        self.queue = []         # other data pending to write\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"Enter the runtime context related to this object.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        \"\"\"Exit the runtime context related to this object.\"\"\"\n",
    "        self.close()\n",
    "\n",
    "    def write(self, fmt, *args):\n",
    "        \"\"\"Pack and write args with format fmt\"\"\"\n",
    "        if fmt != \"n\":\n",
    "            if self.wnibble is None:\n",
    "                fmt = \"!\" + fmt  # big-endian\n",
    "                args = [a.encode('utf-8') if isinstance(a, str) else a for a in args]\n",
    "                self.f.write(pack(fmt, *args))\n",
    "            else:\n",
    "                self.queue.append((fmt, args))\n",
    "        else: # Nibbles still not being used at the final example\n",
    "            if self.wnibble is None:\n",
    "                self.wnibble = (int(args[0]) + 8) & 0xf\n",
    "            else:\n",
    "                self.wnibble <<= 4\n",
    "                self.wnibble |= (int(args[0]) + 8) & 0xf\n",
    "                self.f.write(pack(\"B\", self.wnibble))\n",
    "                self.wnibble = None\n",
    "\n",
    "                for fmt, args in self.queue:\n",
    "                    self.write(fmt, *args)\n",
    "                self.queue = []\n",
    "\n",
    "    def read(self, fmt):\n",
    "        \"\"\"Read data with format fmt and unpack\"\"\"\n",
    "        if fmt != \"n\":\n",
    "            fmt = \"!\" + fmt  \n",
    "            data = self.f.read(calcsize(fmt))\n",
    "            udata = unpack(fmt, data)\n",
    "            return [u.decode('utf-8') if isinstance(u, bytes) else u for u in udata] if len(udata) > 1 else udata[0]\n",
    "        else:\n",
    "            if self.rnibble is not None:\n",
    "                udata = self.rnibble\n",
    "                self.rnibble = None\n",
    "            else:\n",
    "                data = self.f.read(calcsize(\"B\"))\n",
    "                udata = unpack(\"B\", data)[0]\n",
    "                self.rnibble = (udata & 0xf) - 8\n",
    "                udata = (udata >> 4) - 8\n",
    "            return udata\n",
    "\n",
    "    def tell(self):\n",
    "        \"\"\"Return the current file position\"\"\"\n",
    "        return self.f.tell()\n",
    "\n",
    "    def seek(self, offset, whence=0):\n",
    "        \"\"\"Move the file pointer to the specified position\"\"\"\n",
    "        return self.f.seek(offset, whence)\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the file\"\"\"\n",
    "        if self.wnibble is not None:\n",
    "            self.write(\"n\", 0)\n",
    "        self.f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c744db-8c06-4b88-9404-0dc0fe95632d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_progress(message, processed, total):\n",
    "    \"\"\"Print progress message.\"\"\"\n",
    "    print(message % (processed, total))\n",
    "\n",
    "\n",
    "def get_progress(stats, im_data, min_n):\n",
    "    \"\"\"Get progress information for print.\"\"\"\n",
    "    total_blocks = (im_data.shape[0] // min_n) * (im_data.shape[1] // min_n)\n",
    "    processed_blocks = sum(stats.values())\n",
    "    return processed_blocks, total_blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101ed46a-e726-4003-a83d-7085d62d1cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def psi(x):\n",
    "\tif 0 <= x < 0.5:\n",
    "\t\treturn 1\n",
    "\tif 0.5 <= x < 1:\n",
    "\t\treturn -1\n",
    "\treturn 0\n",
    "\n",
    "def phi(x):\n",
    "\tif 0 <= x < 1:\n",
    "\t\treturn 1\n",
    "\treturn 0\n",
    "\n",
    "def DCT_II_f(k, N):\n",
    "    \"\"\"Discrete Cosine Transform Type II\"\"\"\n",
    "    def f(x):\n",
    "        return np.cos(pi * (x + 0.5) * k / N)\n",
    "    return f\n",
    "\n",
    "def h(i, N):\n",
    "    \"\"\"Generate the h function for the Haar basis.\"\"\"\n",
    "    if i == 0:\n",
    "        return phi\n",
    "\n",
    "    n, k = [(n, k) for n in range(int(log(N, 2))) for k in range(2 ** n)][i - 1]\n",
    "    return lambda x: 2 ** (n / 2.0) * psi(2 ** n * x - k)\n",
    "\n",
    "def v(h, N):\n",
    "    \"\"\"Generate the v vector for the Haar basis.\"\"\"\n",
    "    return [h(i / float(N)) for i in range(N)]\n",
    "\n",
    "def w(k, N):\n",
    "\tc = sqrt(2) ** sign(k)\n",
    "\treturn  [ c * DCT_II_f(k, N)(i / float(N)) for i in range(N) ]\n",
    "\n",
    "def W(k1, k2, n, N):\n",
    "    \"\"\"Generate the W matrix for the basis.\"\"\"\n",
    "    def ro(t):\n",
    "        return [[cos(t), -sin(t)], [sin(t), cos(t)]]\n",
    "\n",
    "    def theta(n, N):\n",
    "        return pi * n / (2.0 * N)\n",
    "\n",
    "    def g(k1, k2, N1, N2, v):\n",
    "        return DCT_II_f(k1, N1)(v[0]) * DCT_II_f(k2, N2)(v[1])\n",
    "\n",
    "    def W_elem(i, j):\n",
    "        return g(k1, k2, 8, 8, np.dot(ro(theta(n, N)), [[i / 8.0], [j / 8.0]]))\n",
    "\n",
    "    return [[W_elem(i, j) for j in range(8)] for i in range(8)]\n",
    "\n",
    "def DCT1_qt(rows, cols):\n",
    "    \"\"\"Generate the DCT basis matrix.\"\"\"\n",
    "    return np.array([w(k, rows) for k in range(cols)]).T\n",
    "\n",
    "def Haar1_qt(rows, cols):\n",
    "    \"\"\"Generate the Haar basis matrix.\"\"\"\n",
    "    return np.array([v(h(i, cols), rows) for i in range(cols)]).T\n",
    "\n",
    "def DCT1_Haar1_qt(rows, cols):\n",
    "    \"\"\"Combine DCT and Haar basis matrices.\"\"\"\n",
    "    dct_matrix = DCT1_qt(rows, cols // 2)\n",
    "    haar_matrix = Haar1_qt(rows, cols // 2)\n",
    "    return np.concatenate((dct_matrix, haar_matrix), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b25d105-287e-4232-ad12-45e6059783da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _omp_code(x_list, im_data, im_rec, omp_d, max_error, bi, N, k, stats, ssim_stop, min_n, max_n, callback):\n",
    "    b = im_data.flatten()\n",
    "    \n",
    "    A = omp_d.get(N)\n",
    "    \n",
    "    if A.shape[1] > b.size:\n",
    "        A = A[:, :b.size]\n",
    "    \n",
    "    # Perform OMP on the entire image\n",
    "    omp = OrthogonalMatchingPursuit(n_nonzero_coefs=min(A.shape[1], b.size))\n",
    "    omp.fit(A, b)\n",
    "    x = omp.coef_\n",
    "    \n",
    "    x_list.append((N, x))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df580d5-9f6c-4574-a2ea-df20d25ce586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def code(input_file, output_file, max_error, bi, min_n=MIN_N, max_n=MAX_N):\n",
    "    \"\"\"Compress input_file with the given parameters into output_file\"\"\"\n",
    "    print(\"N\", min_n, max_n)\n",
    "\n",
    "    # STEP 0 - HEADER ###########################\n",
    "    version = FIF_VER\n",
    "\n",
    "    im = Image.open(input_file)\n",
    "    im = im.convert('YCbCr')\n",
    "    w, h = im.size\n",
    "    depth = mode_to_bpp(im.mode) // 8\n",
    "    raw_size = w * h * depth\n",
    "\n",
    "    print(f\"Image Mode: {im.mode}, Depth: {depth}, Width: {w}, Height: {h}\")\n",
    "\n",
    "    with RawFile(output_file, 'wb') as f:\n",
    "        f.write(HEADER_FMT, MAGIC_NUMBER, version, w, h, depth, A_id, bi, min_n, max_n)\n",
    "\n",
    "        # STEP 1 - OMP ###########################\n",
    "        im_data = np.array(im.getdata()).reshape(h, w, depth)\n",
    "        stats = {} \n",
    "        n0_cumu = 0\n",
    "\n",
    "        # Initialize dictionary of sparse vectors for the whole image\n",
    "        omp_d = {}\n",
    "        n = min_n\n",
    "        while n <= max_n:\n",
    "            A = DCT1_Haar1_qt(n * n, A_COLS)\n",
    "            print(f\"Initializing omp_d[{n}] with matrix A of shape {A.shape}\")\n",
    "            omp_d[n] = A\n",
    "            n *= 2\n",
    "\n",
    "        x_list = []\n",
    "\n",
    "        # Process each color channel of the entire image\n",
    "        for k in range(depth): \n",
    "            n0 = _omp_code(x_list, im_data[:, :, k], None, omp_d, max_error, bi, \n",
    "                           max_n, k, stats, ssim_stop, min_n, max_n, callback)\n",
    "            n0_cumu += n0\n",
    "\n",
    "        # Write compressed data\n",
    "        for N, x in x_list:\n",
    "            f.write(\"B\", N)\n",
    "            v_fmt = \".2f\"  \n",
    "            write_vector(f, x.tolist(), v_fmt)\n",
    "\n",
    "        bytes_written = f.tell()\n",
    "\n",
    "    return output_file, bytes_written, raw_size, n0_cumu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065774e2-c48c-4923-817c-14467184ca93",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22504f9e-9627-4a1e-8238-81d57d47aae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N 8 32\n",
      "Image Mode: YCbCr, Depth: 3, Width: 512, Height: 512\n",
      "Initializing omp_d[8] with matrix A of shape (64, 256)\n",
      "Initializing omp_d[16] with matrix A of shape (256, 256)\n",
      "Initializing omp_d[32] with matrix A of shape (1024, 256)\n",
      "Block stats: {32: 99}    Progress: 100/256\n",
      "Block stats: {32: 199}    Progress: 200/256\n",
      "Block stats: {32: 355}    Progress: 100/256\n",
      "Block stats: {32: 455}    Progress: 200/256\n",
      "Block stats: {32: 611}    Progress: 100/256\n",
      "Block stats: {32: 711}    Progress: 200/256\n"
     ]
    }
   ],
   "source": [
    "MIN_N = 8\n",
    "MAX_N = 32\n",
    "A_COLS = 256\n",
    "\n",
    "FIF_VER = 2\n",
    "MAGIC_NUMBER = b'FIF'  # Ensure this is a bytes object\n",
    "HEADER_FMT = '3sBiiBBBBB'\n",
    "\n",
    "\n",
    "V_FMT_PRECISION = \".2f\"  # Use this for floating-point precision formatting\n",
    "\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "    # Your code with OrthogonalMatchingPursuit here\n",
    "\n",
    "    # Example usage\n",
    "    input_file = 'fif_codec/images/input/lena.png'\n",
    "    output_file = 'path_to_output_file.fif'\n",
    "    max_error = 0.1\n",
    "    bi = 0  # Example value for basis index\n",
    "    code(input_file, output_file, max_error, bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100a7009-6a92-454f-bb5d-903cd3a265d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Algorithm 2: Decoder\n",
    "<font color=\"red\">Input </font>: input_file, output_file  \n",
    "<font color=\"red\">Output </font>: decoded_image\n",
    "\n",
    "1. Open the raw file and read header with MAGIC_NUMBER, version, w, h, depth, A_id, bi, min_n, max_n\n",
    "2. Initialize image data matrix with zeros\n",
    "\n",
    "3. For each color channel (depth):\n",
    "   3.1 Decode the blocks using the OMP recursive decoder\n",
    "   3.2 Reconstruct the image from decoded blocks\n",
    "\n",
    "4. Convert YCbCr to RGB if needed\n",
    "5. Save the decoded image to output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3e35caa-9ab1-44ae-ac09-89415883b4ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from struct import unpack, calcsize\n",
    "import zlib\n",
    "import io\n",
    "\n",
    "def decode(input_file, output_file):\n",
    "    \"\"\"Decompress input_file into output_file\"\"\"\n",
    "\n",
    "    with RawFile(input_file, 'rb') as f:\n",
    "        #Chequear porque me parece no recuerdo  A_id, bi, minN, maxN si los guardé con el encoder.\n",
    "        #En particular, la variable  A_id la borré de todo el código\n",
    "        mn, version, w, h, depth, A_id, bi, minN, maxN = f.read(HEADER_FMT) \n",
    "\n",
    "        if mn != MAGIC_NUMBER.decode():\n",
    "            raise Exception(f\"Invalid image format: Wrong magic number '{mn}'\")\n",
    "\n",
    "        if version != FIF_VER:\n",
    "            raise Exception(f\"Invalid codec version: {version}. Expected: {FIF_VER}\")\n",
    "\n",
    "        im_data = np.zeros((h, w, depth), dtype=np.float32)\n",
    "\n",
    "        # Process image for each channel\n",
    "        for k in range(depth):\n",
    "            _omp_decode(f, im_data[:, :, k], bi, maxN, minN, maxN)\n",
    "\n",
    "        if depth == 1:\n",
    "            im_data[:, :, 1] = im_data[:, :, 0]\n",
    "            im_data[:, :, 2] = im_data[:, :, 0]\n",
    "\n",
    "        YCbCr_to_RGB(im_data)\n",
    "\n",
    "        im = Image.fromarray(im_data.astype('uint8'))\n",
    "        im.save(output_file)\n",
    "\n",
    "def _omp_decode(f, im_data, bi, N, minN, maxN):\n",
    "    \"\"\"OMP decoder for the entire image\"\"\"\n",
    "\n",
    "    A = DCT1_Haar1_qt(N * N, A_COLS)\n",
    "\n",
    "    v_fmt = V_FMT_PRECISION\n",
    "\n",
    "    # Read the vector x from the file\n",
    "    x = np.array(read_vector(f, v_fmt))\n",
    "\n",
    "    # Compute the output vector b = A * x\n",
    "    b = np.dot(A, x)\n",
    "\n",
    "    for l in range(len(b)):\n",
    "        b[l] = truncate(b[l], \"B\")\n",
    "\n",
    "    # Reconstruct the image data ( c_inv still not defined. Found in biyections.py)\n",
    "    im_data[:, :] = c_inv[bi](b, N).reshape(im_data.shape)\n",
    "\n",
    "def read_vector(f, v_fmt):\n",
    "    \"\"\"Read vector from file f with format v_fmt\"\"\"\n",
    "    x = read_vector_as_pairs(f, v_fmt)\n",
    "    quantize_inv(x, v_fmt)\n",
    "    return x\n",
    "\n",
    "def YCbCr_to_RGB(im_data):\n",
    "    \"\"\"Convert YCbCr to RGB.\"\"\"\n",
    "    Y = im_data[:, :, 0]\n",
    "    Cb = im_data[:, :, 1] - 128\n",
    "    Cr = im_data[:, :, 2] - 128\n",
    "\n",
    "    R = Y + 1.402 * Cr\n",
    "    G = Y - 0.344136 * Cb - 0.714136 * Cr\n",
    "    B = Y + 1.772 * Cb\n",
    "\n",
    "    im_data[:, :, 0] = np.clip(R, 0, 255)\n",
    "    im_data[:, :, 1] = np.clip(G, 0, 255)\n",
    "    im_data[:, :, 2] = np.clip(B, 0, 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5473c85b-707f-4ef3-a5e0-3ac42424b41c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected vector of length .2f, but got 70",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m input_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_output_file.fif\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreconstructed_image.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 11\u001b[0m decode(input_file, output_file)\n",
      "Cell \u001b[1;32mIn[12], line 27\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(input_file, output_file)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mBytesIO(decompressed_data) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(depth):\n\u001b[1;32m---> 27\u001b[0m             _omp_decode(f, im_data, im_rec, bi, maxN, minN, maxN, k)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m depth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     30\u001b[0m     im_data[:, :, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m im_data[:, :, \u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[12], line 58\u001b[0m, in \u001b[0;36m_omp_decode\u001b[1;34m(f, im_data, im_rec, bi, N, minN, maxN, k)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(N)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# _omp_decode(f, im_data, sub_rec, bi, N // 2, minN, maxN, k)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# continue\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(read_vector(f, v_fmt))\n\u001b[0;32m     59\u001b[0m b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(A, x)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(b)):\n",
      "Cell \u001b[1;32mIn[12], line 77\u001b[0m, in \u001b[0;36mread_vector\u001b[1;34m(f, expected_length)\u001b[0m\n\u001b[0;32m     75\u001b[0m n \u001b[38;5;241m=\u001b[39m unpack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, f\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Read the length byte\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m!=\u001b[39m expected_length:\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected vector of length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     78\u001b[0m x \u001b[38;5;241m=\u001b[39m unpack(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m, f\u001b[38;5;241m.\u001b[39mread(expected_length \u001b[38;5;241m*\u001b[39m struct\u001b[38;5;241m.\u001b[39mcalcsize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mValueError\u001b[0m: Expected vector of length .2f, but got 70"
     ]
    }
   ],
   "source": [
    "HEADER_FMT = '3sBiiBBBBB'\n",
    "MAGIC_NUMBER = b'FIF'\n",
    "FIF_VER = 2\n",
    "A_COLS = 256\n",
    "V_FMT_PRECISION = \".2f\"\n",
    "\n",
    "\n",
    "input_file = 'path_to_output_file.fif'\n",
    "output_file = 'reconstructed_image.png'\n",
    "\n",
    "decode(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
